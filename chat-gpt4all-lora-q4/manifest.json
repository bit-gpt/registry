{
    "id": "gpt4all-lora-q4",
    "name": "GPT4ALL-Lora Q4",
    "icon": "",
    "description": "GPT4ALL-Lora Q4",
    "documentation": "",
    "modelInfo": {
        "maxLength": 12000,
        "tokenLimit": 4000,
        "weightsName": "vicuna-7b-q4.bin",
        "weightsSize": 4212859520,
        "memoryRequirements": "8gb",
        "inferenceTime": "5 tokens per second",
        "devices": [
            "cpu"
        ]
    },
    "interfaces": [
        "chat",
        "embeddings"
    ],
    "dockerImage": "ghcr.io/premai-io/chat-gpt4all-lora-q4-cpu:latest",
    "dockerImageGPU": "",
    "defaultPort": 8002
}
