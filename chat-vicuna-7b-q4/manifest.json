{
    "id": "vicuna-7b-q4",
    "name": "Vicuna 7B Q4",
    "description": "Vicuna is an open-source chatbot, fine-tuned on LLaMA using conversations from ShareGPT. Developed collaboratively by a team from UC Berkeley, CMU, Stanford, and UC San Diego, this auto-regressive language model aims to advance research in large language models and chatbots. Primarily designed for researchers and hobbyists in AI and NLP, the model undergoes preliminary evaluations using diverse questions and GPT-4 for output judgment. The current model has been 4-bit quantized using ggml framework. [Learn More](https://vicuna.lmsys.org/)",
    "documentation": "",
    "icon": "",
    "modelInfo": {
        "maxLength": 12000,
        "tokenLimit": 4000,
        "weightsName": "vicuna-7b-q4.bin",
        "weightsSize": 4212859520,
        "memoryRequirements": "8gb",
        "inferenceTime": "5 tokens per second"
    },
    "interfaces": [
        "chat",
        "embeddings"
    ],
    "dockerImages": {
        "cpu": {
            "dockerImage": "ghcr.io/premai-io/chat-vicuna-7b-q4-cpu:latest"
        }
    },
    "defaultPort": 8001
}
